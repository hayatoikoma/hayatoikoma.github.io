<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Hayato Ikoma</title>
</head>
<body>
<div id="layout-content">
<div id="toptitle">
<h1>Hayato Ikoma</h1>
</div>
<h2>Contact</h2>
<p>Email: hayato.ikoma(at)10xgenomics(dot)com
</p>
<p>Github: <a href="https://github.com/hayatoikoma" target=&ldquo;blank&rdquo;>https://github.com/hayatoikoma</a>
</p>
<h2>Intro</h2>
<p>I am working on computational imaging and image analysis problems related to in-situ multiomics imaging technologies at <a href="https://www.10xgenomics.com/" target=&ldquo;blank&rdquo;>10x Genomics</a> and am a former Ph.D. student of <a href="http://www.computationalimaging.org/" target=&ldquo;blank&rdquo;>Stanford Computational Imaging Group</a> at Department of Electrical Engineering, Stanford University. For my Ph.D. research, I was focusing on the development of computational imaging techniques for fluorescence optical microscopy, and I am broadly interested in signal processing, machine learning and optimization. Particularly, most of my Ph.D. works focused on the end-to-end optimization of optical imaging systems, which involves machine learning and micro fabrication of an optical element. I also served as a teaching assistant for <a href="https://stanford.edu/class/ee267/" target=&ldquo;blank&rdquo;>EE267: Virtual Reality</a> for five years and have written the template of homework in JavaScript with Three.js.
</p>
<p>Before coming to Stanford University, I worked on new computational imaging techniques for fluorescence optical microscopy and a space telescope at MIT Media Lab and Centre de Mathématiques et Leurs Applications at École Normal Supérieure de Cachan (CMLA, ENS Cachan) in France. I also worked on an image processing algorithm for head-mount displays at the Google's Daydream team and a learning-based computational photography at the Google's Perception team as an intern. My work at Google contributed to <a href="https://ai.googleblog.com/2021/02/the-technology-behind-cinematic-photos.html" target=&ldquo;blank&rdquo;>Cinematic Photos of Google Photos</a>.
</p>
<h2>Education</h2>
<p>Ph.D., <a href="https://ee.stanford.edu/" target=&ldquo;blank&rdquo;>Electrical Enginnering</a>, Stanford University, Sept 2015 - June 2021
</p>
<ul>
<li><p>Project: Computational Imaging for Fluorescence Optical Microscopy
</p>
</li>
</ul>
<ul>
<li><p>Supervised by <a href="http://web.stanford.edu/~gordonwz/" target=&ldquo;blank&rdquo;>Gordon Wetzstein</a>
</p>
</li>
</ul>
<p>M.S., <a href="http://www.math.ens-cachan.fr/version-francaise/formations/master-mva/" target=&ldquo;blank&rdquo;>Applied Mathematics</a>, Ecole normale supérieure de Cachan, July 2015
</p>
<ul>
<li><p>Program: M2 MVA Mathématiques/Vision/Apprentissage (Mathematics/Commputer Vision/Machine Learning)
</p>
</li>
</ul>
<ul>
<li><p>Project: Phase Diversity: Estimation of an Optical Wavefront from Landscape Images
</p>
</li>
</ul>
<ul>
<li><p>Supervised by <a href="https://sites.google.com/site/jeanmichelmorelcmlaenscachan/" target=&ldquo;blank&rdquo;>Jean-Michel Morel</a>
</p>
</li>
</ul>
<ul>
<li><p><a href="http://cmla.ens-paris-saclay.fr/version-anglaise/" target=&ldquo;blank&rdquo;>Centre de mathématiques et de leurs applications (CMLA)</a>
</p>
</li>
</ul>
<p>M.S., <a href="https://www.media.mit.edu/" target=&ldquo;blank&rdquo;>Media Arts and Sciences</a>, Massachusetts Institute of Technology, June 2014
</p>
<ul>
<li><p>Project: Attenuation-corrected Fluorescence Spectra Unmixing for Spectroscopy and Microscopy
</p>
</li>
</ul>
<ul>
<li><p>Supervised by <a href="http://cameraculture.media.mit.edu/" target=&ldquo;blank&rdquo;>Ramesh Raskar</a>
</p>
</li>
</ul>
<ul>
<li><p>MIT Media Lab
</p>
</li>
</ul>
<p>M.S., <a href="http://www.biophys.kyoto-u.ac.jp/index_e.php" target=&ldquo;blank&rdquo;>Biophysics</a>, Kyoto University, March 2012
</p>
<ul>
<li><p>Project: Analysis of Dynamics of Actin Bundles in Fish Epidermal Keratocytes
</p>
</li>
</ul>
<ul>
<li><p>Supervised by <a href="http://www.cespi.nagoya-u.ac.jp/Eng/" target=&ldquo;blank&rdquo;>Yoshinori Fujiyoshi</a>
</p>
</li>
</ul>
<p>B.E., <a href="http://www.material.t.u-tokyo.ac.jp/e/" target=&ldquo;blank&rdquo;>Materials Engineering</a>, University of Tokyo, March 2010
</p>
<ul>
<li><p>Project: Electrical Property Measurement of Germanium Crystal Based on Rapid Melt Growth
</p>
</li>
</ul>
<ul>
<li><p>Supervised by <a href="http://www.adam.t.u-tokyo.ac.jp/" target=&ldquo;blank&rdquo;>Akira Toriumi</a>, <a href="http://www.scio.t.u-tokyo.ac.jp/top-eng.html" target=&ldquo;blank&rdquo;>Koji Kita</a>, <a href="http://webpark1753.sakura.ne.jp/nagashio_lab_E/" target=&ldquo;blank&rdquo;>Kosuke Nagashio</a>
</p>
</li>
</ul>
<h2>Scholarships</h2>
<p><a href="https://www.fondation-hadamard.fr/en" target=&ldquo;blank&rdquo;>Jacques Hadamard Mathematics Foundation</a> (9/2014 - 6/2015)
</p>
<p><a href="http://funaifoundation.jp/" target=&ldquo;blank&rdquo;>Funai Overseas Scholarship</a> (9/2012 - 5/2014)
</p>
<p>Iwadare Scholarhip (4/2011 - 3/2012)
</p>
<h2>Working experience</h2>
<p>Google Inc., June 2019 - December 2019
</p>
<ul>
<li><p>Research intern / Student researcher
</p>
</li>
<li><p>Project: Development of Monocular Depth Estimation Model for Computational Photography
</p>
</li>
</ul>
<p>Google Inc., June 2016 - September 2016
</p>
<ul>
<li><p>Software engineering intern
</p>
</li>
<li><p>Project: Development of Efficient Image Processing Algorithms for Head-mount Displays
</p>
</li>
</ul>
<h2>Teaching experience</h2>
<p>Teaching assistant: <a href="https://stanford.edu/class/ee267/" target=&ldquo;blank&rdquo;>EE267: Virtual Reality (Sprint 2017, Spring 2018, Spring 2019, Spring 2020, Spring 2021)</a>
</p>
<ul>
<li><p>This class was previously taught in C++/OpenGL in 2016, and we revised all homework to use JavaScript/WebGL as a rendering platform for our DIY head-mount displays. For this transition, I was responsible for the re-implementation of all homework in Javascript with Three.js. (Its source code is available upon request.)
</p>
</li>
</ul>
<h2>Publications</h2>
<ul>
<li><p>Ikoma, H., Kudo, T., Peng, Y., Broxton, M. and Wetzstein, G., &ldquo;Deep Learning Multi-shot 3D Localization
Microscopy Using Hybrid Optical–electronic Computing,&rdquo; Optics Letters, 2021. 
<a href="https://www.computationalimaging.org/publications/localization-microscopy/" target=&ldquo;blank&rdquo;>[website]</a> <a href="https://opg.optica.org/ol/abstract.cfm?uri=ol-46-24-6023" target=&ldquo;blank&rdquo;>[paper]</a>
</p>
</li>
</ul>
<ul>
<li><p>Arguello, H., Pinilla, S., Peng, Y., Ikoma, H.,Bacca, J. and Wetzstein, G., &ldquo;Shift-variant Color-coded Diffractive Spectral Imaging System,&rdquo; Optica, 8, 1424-1434, 2021. <a href="https://jorgebaccauis.github.io/"" target=&ldquo;blank&rdquo;>[website]</a> <a href="https://www.osapublishing.org/optica/fulltext.cfm?uri=optica-8-11-1424&amp;id=464500" target=&ldquo;blank&rdquo;>[paper]</a>
</p>
</li>
</ul>
<ul>
<li><p>Ikoma, H., Nguyen, C., Metzler, C., Peng, Y., and Wetzstein, G., &ldquo;Depth from Defocus with Learned Optics for Imaging and Occlusion-aware Depth Estimation,&rdquo; 2021 IEEE International Conference on Computational Photography (ICCP), 2021, pp. 1-12  <a href="https://www.computationalimaging.org/publications/deepopticsdfd/" target=&ldquo;blank&rdquo;>[website]</a> <a href="https://ieeexplore.ieee.org/abstract/document/9466261" target=&ldquo;blank&rdquo;>[paper]</a>
</p>
</li>
</ul>
<ul>
<li><p>Wetzstein, G., Ikoma, H., Metzler, C., and Peng, Y., &ldquo;Deep Optics: Learning Cameras and Optical Computing Systems,&rdquo; 2020 54th Asilomar Conference on Signals, Systems, and Computers, 2020, pp. 1313-1315, <a href="https://ieeexplore.ieee.org/abstract/document/9443575" target=&ldquo;blank&rdquo;>[paper]</a>
</p>
</li>
</ul>
<ul>
<li><p>Baek, S., Ikoma, H., Jeon, D., Li, Y., Heidrich, W., Wetzstein, G., Kim, Mi., &ldquo;End-to-End Hyperspectral-Depth Imaging with Learned Diffractive Optics,&rdquo; arXiv:200900463, ICCV 2021 <a href="https://arxiv.org/abs/2009.00463" target=&ldquo;blank&rdquo;>[paper]</a>
</p>
</li>
</ul>
<ul>
<li><p>Dun, X., Ikoma, H., Wetzstein, G., Wang, Z., Cheng, X., and Peng, Y., “Learned rotationally symmetric diffractive achromat for full-spectrum computational imaging,” Optica 7, 913-922, 2020. <a href="https://www.computationalimaging.org/publications/learned-rotationally-symmetric-diffractive-achromat/" target=&ldquo;blank&rdquo;>[website]</a> <a href="https://www.osapublishing.org/optica/abstract.cfm?uri=optica-7-8-913" target=&ldquo;blank&rdquo;>[paper]</a>
</p>
</li>
</ul>
<ul>
<li><p>Metzler, C., Ikoma, H., Peng, Y., and Wetzstein, G. “Deep Optics for Single-shot High-dynamic-range Imaging,” Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020. <a href="https://www.computationalimaging.org/publications/deep-optics-hdr/" target=&ldquo;blank&rdquo;>[website]</a> <a href="https://arxiv.org/abs/1908.00620" target=&ldquo;blank&rdquo;>[paper]</a>
</p>
</li>
</ul>
<ul>
<li><p>Ikoma, H., Broxton, M., Kudo, T., and Wetzstein, G. &ldquo;A convex 3D deconvolution algorithm for low photon count fluorescence imaging.&rdquo; Scientific Reports, 11489, 2018. <a href="http://www.computationalimaging.org/publications/3d-deconvolution-for-low-photon-count-fluorescence-imaging-scientific-reports-2018/" target=&ldquo;blank&rdquo;>[website]</a> <a href="https://www.nature.com/articles/s41598-018-29768-x" target=&ldquo;blank&rdquo;>[paper]</a> <a href="https://github.com/computational-imaging/ThreeDeconv.jl" target=&ldquo;blank&rdquo;>[software]</a> 
</p>
</li>
</ul>
<ul>
<li><p>Ikoma, H., Heshmat, B, Wetzstein, G, and Raskar, R. “Attenuation-corrected fluorescence spectra unmixing for spectroscopy and microscopy.” Optics Express, 22(16):19469–19483, 2014. <a href="https://www.osapublishing.org/oe/abstract.cfm?uri=oe-22-16-19469" target=&ldquo;blank&rdquo;>[paper]</a>
</p>
</li>
</ul>
<ul>
<li><p>Goda, M. Ohata, M., Ikoma, H., Fujiyoshi, Y., Sugimoto, M., and Fujii, R. “Integumental reddish-violet coloration owing to novel dichromatic chromatophores in the teleost fish, Pseudochromis diadema.” Pigment Cell &amp; Melanoma Research, 24(4):614–617, 2012. <a href="http://onlinelibrary.wiley.com/doi/10.1111/j.1755-148X.2011.00861.x/full" target=&ldquo;blank&rdquo;>[paper]</a>
</p>
</li>
</ul>
<h2>Abstracts</h2>
<ul>
<li><p>Ikoma, H., Peng, Y., Broxton, B., and Wetzstein, G. “Snapshot multi-PSF 3D single-molecule localization microscopy using deep learning,” in Imaging and Applied Optics Congress, OSA Technical Digest, paper CW3B.3., 2020 <a href="https://www.osapublishing.org/abstract.cfm?uri=COSI-2020-CW3B.3" target=&ldquo;blank&rdquo;>[link]</a>
</p>
</li>
</ul>
<ul>
<li><p>Heshmat, B., Ikoma, H., Lee, I. H., Rastogi, K., and Raskar, R. “Computational hair quality categorization in lower magnifications,” in Proceeding of SPIE 9333, Biomedical Applications of Light Scattering IX, 93330Z, 2015 <a href="http://spie.org/Publications/Proceedings/Paper/10.1117/12.2078027" target=&ldquo;blank&rdquo;>[link]</a>
</p>
</li>
</ul>
<ul>
<li><p>Ikoma, H., Heshmat, B., Wetzstein, G., and Raskar, R. “Nonlinear fluorescence spectral unmixing” in CLEO, OSA Technical Digest, JTh2A.9., 2014 <a href="https://www.osapublishing.org/abstract.cfm?uri=CLEO_QELS-2014-JTh2A.9" target=&ldquo;blank&rdquo;>[link]</a>
</p>
</li>
</ul>
<ul>
<li><p>Kadambi, A., Ikoma, H., Lin, X., Wetzstein, G., and Raskar, R. “Subsurface Enhancement through Sparse Representations of Multispectral Direct/Global Decomposition.” in Imaging and Applied Optics, OSA Technical Digest, CTh1B.4., 2013 <a href="https://www.osapublishing.org/abstract.cfm?uri=COSI-2013-CTh1B.4" target=&ldquo;blank&rdquo;>[link]</a>
</p>
</li>
</ul>
<h2>Workshops / Presentations</h2>
<ul>
<li><p>Ikoma, H., Broxton, M., Kudo, T., and Wetzstein, G., &ldquo;A convex 3D deconvolution algorithm for low photon count fluorescence imaging,&rdquo; Olympus Corporation, July 2018
</p>
</li>
</ul>
<ul>
<li><p>Ikoma, H., Konrad, R., Padmanaban, N., and Molner, K., &ldquo;Build Your Own VR Display: An Introduction to VR Display Systems for Hobbyists and Educators,&rdquo; Electronic Imaging Short Courses, January 2018, January 2019
</p>
</li>
</ul>
<ul>
<li><p>Wetzstein, G., Konrad, R., Padmanaban, N., and Ikoma, H., &ldquo;Build Your Own VR Display: An Introduction to VR Display Systems for Hobbyists and Educators,&rdquo; SIGGRAPH, August 2017 <a href="http://s2017.siggraph.org/courses/events/build-your-own-vr-display-introduction-vr-display-systems-hobbyists-and-educators.html" target=&ldquo;blank&rdquo;>[Link]</a>
</p>
</li>
</ul>
<ul>
<li><p>Ikoma, H., Delvit, J., Latry, C., Thiebaut, C., and Morel, J.“Phase Diversity: Estimation of an Optical Wavefront from Landscape Images,” Le site du Centre national d&rsquo;études spatiales (CNES), 2015
</p>
</li>
</ul>
<ul>
<li><p>Ikoma, H., Delvit, J., Latry, C., Thiebaut, C., and Morel, J.“Phase Diversity: Estimation of an Optical Wavefront from Landscape Images,” Applied Inverse Problems conference, May 2015
</p>
</li>
</ul>
<h2>Programming skills</h2>
<ul>
<li><p>Python, JavaScript, Julia, C++, MATLAB
</p>
</li>
</ul>
<h2>Research skills</h2>
<ul>
<li><p>image processing, computer vision, convolutional neural net,
computational imaging/photography, optics, grayscale photolithography, etc
</p>
</li>
</ul>
<h2>Resume</h2>
<p><a href="resume.pdf">[resume.pdf]</a>
</p>
<div id="footer">
<div id="footer-text">
Page generated 2022-04-12 23:17:15 PDT, by <a href="https://github.com/wsshin/jemdoc_mathjax" target="blank">jemdoc+MathJax</a>.
(<a href="index.jemdoc">source</a>)
</div>
</div>
</div>
</body>
</html>
